{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Deep Melanoma Classifier</center></h1>\n",
    "\n",
    "\n",
    "[Melanoma](https://www.mayoclinic.org/diseases-conditions/melanoma/symptoms-causes/syc-20374884) is the most serious type of skin cancer, develops in the cells (melanocytes) that produce melanin, early diagnosis is key for recovery.\n",
    "\n",
    "This web app outputs the probability of Melanoma in images of skin lesions uploaded by the user. The user can also choose the number of [Test Time Augmentation](https://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d) (T.T.A.) to get more accurate predictions. \n",
    "    \n",
    "<h3>Directions For Use:</h3>   \n",
    "\n",
    "    \n",
    "1. Select the desired # of Test Time Augmentations using the slider.\n",
    "2. Upload an image of the skin lesion you want to check for Melanoma.\n",
    "\n",
    "<h3>Outputs</h3>\n",
    "\n",
    "1. The user, in realtime, will see the test time augmentations being applied and the corresponding model prediction.\n",
    "2. At the end, The final prediction (avergae of all TTA predictions) is displayed along with the original image uploaded.\n",
    "\n",
    "<font color='red'>**NOTE:**</font> This is a proof of concept for research purposes ONLY. Always seek professional medical help in a clinical setting for final diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the req libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import efficientnet.tfkeras as efn\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import io\n",
    "from ipywidgets import VBox, Layout\n",
    "from tensorflow.keras.preprocessing.image import apply_affine_transform\n",
    "import time\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import sys, os\n",
    "\n",
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## download model weights\n",
    "! python download_gdrive.py 1Glog8ezbSN-cbZ49UZsL1C9U1AUr_5P0 EfficientNetB5-weights.15.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the model\n",
    "def getModel():\n",
    "    model_input = tf.keras.Input(shape=(248, 248, 3), name='imgIn')\n",
    "    dummy = tf.keras.layers.Lambda(lambda x:x)(model_input)    \n",
    "    outputs = []    \n",
    "\n",
    "    ## get the attributes of efn - effNet\n",
    "    with suppress_stdout():\n",
    "        constructor = getattr(efn, 'EfficientNetB5');\n",
    "        ## remove top, use imagenet weights\n",
    "        x = constructor(include_top=False, weights='imagenet', \n",
    "                        input_shape=(248, 248, 3), \n",
    "                        pooling='avg')(dummy)\n",
    "\n",
    "    ## add a dense layer\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    outputs.append(x)\n",
    "    \n",
    "    ## create model\n",
    "    model = tf.keras.Model(model_input, outputs, name='effb5')\n",
    "    return model\n",
    "\n",
    "model = getModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('EfficientNetB5-weights.15.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##upload button\n",
    "btn_upload = widgets.FileUpload(accept ='image/*'\n",
    "                                , multiple = True\n",
    "                                , align_items='center'\n",
    "                                ,layout=Layout(margin='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## slider for tta\n",
    "sldr = widgets.IntSlider(value=10\n",
    "                         , min=5\n",
    "                         , max=50\n",
    "                         , step=1\n",
    "#                         , description='T.T.A.:'\n",
    "                         , disabled=False\n",
    "                         , continuous_update=False\n",
    "                         , orientation='horizontal'\n",
    "                         , align_items='center'\n",
    "                         , readout=True\n",
    "                         , readout_format='d'\n",
    "                         , layout=Layout(margin='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = widgets.Output(layout=Layout(margin='auto'))\n",
    "lbl_pred = widgets.Label(layout=Layout(margin='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the onclick event for upload button\n",
    "def on_click(change):\n",
    "    img = widgets.Image(value = btn_upload.data[-1])\n",
    "    out.clear_output()\n",
    "    with out: display(img)\n",
    "    image1 = Image.open(io.BytesIO(btn_upload.data[-1]))\n",
    "    image = np.array(image1)\n",
    "    pred_ls =[]\n",
    "    for i in range(sldr.value):\n",
    "        ## convert to tensor \n",
    "        image = tf.convert_to_tensor(image, tf.float32)\n",
    "        image = tf.image.resize(image, [256,256])\n",
    "        image = np.array(image)\n",
    "\n",
    "        ## translation\n",
    "        transformation = apply_affine_transform(image\n",
    "                                                , tx = (np.random.normal(0, 1, 1)[0])*6\n",
    "                                                , ty = (np.random.normal(0, 1, 1)[0])*6)\n",
    "        ## rotation \n",
    "        transformation = apply_affine_transform(transformation\n",
    "                                                , theta = 180 * (np.random.normal(0, 1, 1)[0]))\n",
    "        ## zoom\n",
    "        transformation = apply_affine_transform(transformation\n",
    "                                                , zx = 1 + (np.random.normal(0, 1, 1)[0])/6\n",
    "                                                , zy = 1 + (np.random.normal(0, 1, 1)[0])/6)\n",
    "        ## shear\n",
    "        transformation = apply_affine_transform(transformation\n",
    "                                                , shear = (np.random.normal(0, 1, 1)[0])*1.5\n",
    "                                                )\n",
    "        img1 = tf.image.random_flip_left_right(transformation)\n",
    "        img1 = tf.image.random_hue(img1, 0.01)\n",
    "        img1 = tf.image.random_saturation(img1, 0.7, 1.3)\n",
    "        #img1 = tf.image.random_contrast(img1, 0.8, 1.2)\n",
    "        img1 = tf.image.random_brightness(img1, 0.1)\n",
    "        img1 = tf.image.random_crop(img1, [250, 250, 3])\n",
    "\n",
    "        img1 = tf.cast(img1, tf.float32) / 255.0\n",
    "        input_arr = tf.image.resize(img1, [248,248])\n",
    "        input_arr = tf.reshape(input_arr, [248,248, 3])\n",
    "        out.clear_output()\n",
    "        img2 = Image.fromarray(((np.array(input_arr)*255).astype(np.int8)), 'RGB')\n",
    "        with out: display(img2)\n",
    "        input_arr = tf.expand_dims(input_arr, axis=0)\n",
    "        pred = model.predict(input_arr, batch_size=1)[0][0]\n",
    "        pred_ls.append(pred)\n",
    "        lbl_pred.value = f'T.T.A. # {i+1} Prediction :{ str(round(pred,2))}'\n",
    "        # Wait for 5 seconds\n",
    "        time.sleep(5)\n",
    "    \n",
    "    out.clear_output()\n",
    "    img = image1.resize((248,248))\n",
    "    with out: display(img)\n",
    "    ans = str(round(np.mean(pred_ls),2))    \n",
    "    lbl_pred.value = f'Final Result - Probability of Melanoma :{ ans}'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_upload.observe(on_click, names=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31af15fb3d0a4a5bb94fe35da8d58cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Select the # Test Time Augmentations ( T.T.A. )'), IntSlider(value=10, continuous_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##organize widgets\n",
    "display(VBox([widgets.Label('Select the # Test Time Augmentations ( T.T.A. ) using the slider',layout=Layout(margin='auto'))\n",
    "              , sldr\n",
    "              , widgets.Label('Upload your image',layout=Layout(margin='auto'))\n",
    "              , btn_upload\n",
    "              , out\n",
    "              ,lbl_pred]\n",
    "             , layout=Layout(border='solid'\n",
    "                             ,width='50%'\n",
    "                             ,margin='auto'))\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes - \n",
    "\n",
    "-  The Inference model in this app is based on the EfficientNet B5 architecture, trained on the [SIIM](https://siim.org/) Melanoma dataset.\n",
    "- The model achieves SOTA performance of 0.9339 AUROC on the test data utilizing heavy Test Time Augmentation, 55 to be exact.\n",
    "- Feel free to check out the GitHub repo for the scripts and details to train the model.\n",
    "- The binder docker is sometimes slow, be patient with the App runtime.\n",
    "\n",
    "##### PhaleoHealth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
